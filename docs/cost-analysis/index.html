<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Medical LLM Research</title><style>*{margin:0;padding:0;box-sizing:border-box}body{font-family:Arial,sans-serif;line-height:1.6;color:#333;background-color:#f4f4f9;overflow-x:hidden}a{color:#007bff;text-decoration:none}a:hover{text-decoration:underline}header{padding:1rem;text-align:center;background-color:#007bff;color:#fff;position:relative}header h1{margin-bottom:.5rem;font-size:1.5rem;word-wrap:break-word}nav{display:flex;justify-content:center;flex-wrap:wrap;gap:1rem;margin-top:.5rem}nav a{color:#fff;padding:.5rem 1rem;border-radius:4px;background-color:#ffffff1a;transition:background-color .3s}nav a:hover{background-color:#fff3;text-decoration:none}main{padding:1rem;background-color:#fff;min-height:calc(100vh - 120px);margin:0 auto;max-width:1200px}main h1,main h2,main h3{margin-top:1rem;word-wrap:break-word}main p{margin-bottom:1rem;word-wrap:break-word}main ul{margin-bottom:1rem;padding-left:1.5rem}main table{width:100%;border-collapse:collapse;margin-bottom:1rem;display:block;overflow-x:auto}main table th,main table td{border:1px solid #ddd;padding:.5rem;text-align:left;min-width:100px}main table th{background-color:#f4f4f9}.content-grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(250px,1fr));gap:1rem;margin-bottom:2rem}.content-grid article{background-color:#fff;padding:1rem;border-radius:5px;box-shadow:0 2px 4px #0000001a;border:1px solid #eee}.content-grid h3{margin-bottom:.5rem}.content-grid p{margin-bottom:1rem}.button{display:inline-block;padding:.75rem 1.5rem;background-color:#007bff;color:#fff;text-decoration:none;border-radius:5px;transition:background-color .3s;border:none;font-size:1rem;cursor:pointer;min-width:200px;text-align:center}.button:hover{background-color:#0056b3;transform:translateY(-2px);box-shadow:0 4px 8px #0000001a}.quick-nav{display:flex;flex-direction:column;gap:.5rem;margin-top:2rem}.quick-nav a{display:block;padding:.75rem;background-color:#007bff;color:#fff;text-align:center;text-decoration:none;border-radius:5px;transition:background-color .3s;min-width:auto}.quick-nav a:hover{background-color:#0056b3}.menu-toggle{display:none;flex-direction:column;justify-content:space-between;width:30px;height:21px;background:transparent;border:none;cursor:pointer;padding:0;z-index:10}.hamburger span{display:block;height:3px;width:100%;background:#fff;border-radius:3px;transition:all .3s ease-in-out}@media(max-width:768px){header{padding:.75rem 1rem}header h1{font-size:1.25rem;margin-bottom:.25rem}nav{position:absolute;top:100%;left:0;width:100%;background-color:#007bff;flex-direction:column;align-items:center;padding:1rem 0;display:none;gap:.5rem}nav.active{display:flex}nav a{width:90%;text-align:center}.menu-toggle{display:flex;position:absolute;top:1.2rem;right:1rem}main{padding:1rem .5rem;min-height:calc(100vh - 100px)}.content-grid{grid-template-columns:1fr;gap:1rem}.quick-nav{flex-direction:column}.quick-nav a{width:100%}.button{min-width:150px;padding:.75rem 1rem}}@media(max-width:480px){header h1{font-size:1.1rem}main{padding:.75rem .25rem}.button{min-width:140px;padding:.6rem .8rem;font-size:.9rem}main table{font-size:.85rem}main table th,main table td{min-width:80px;padding:.3rem}}
</style></head> <body> <header> <h1>Medical LLM & VLM Benchmarks</h1> <button class="menu-toggle" aria-label="Toggle navigation menu"> <div class="hamburger"> <span></span> <span></span> <span></span> </div> </button> <nav> <a href="/research-medical-llm/">Home</a> <a href="/research-medical-llm/docs/llm-benchmarks/">LLM Benchmarks</a> <a href="/research-medical-llm/docs/vlm-benchmarks/">VLM Benchmarks</a> <a href="/research-medical-llm/docs/cost-analysis/">Cost Analysis</a> </nav> </header> <script type="module">document.addEventListener("DOMContentLoaded",function(){const n=document.querySelector(".menu-toggle"),e=document.querySelector("nav");n&&e&&(n.addEventListener("click",function(){e.classList.toggle("active")}),document.querySelectorAll("nav a").forEach(t=>{t.addEventListener("click",()=>{e.classList.remove("active")})}))});</script> <main> <h1 id="cost-analysis-api-vs-self-deployment">Cost Analysis: API vs Self-Deployment</h1>
<h3 id="1-proprietary-api-pricing-models"><strong>1. Proprietary API Pricing Models</strong></h3>
<p>Model seperti GPT-4 atau Gemini dikembangkan oleh perusahaan swasta dan diakses melalui platform berbayar. Struktur biayanya meliputi:</p>
<ul>
<li><strong>Usage-Based Pricing:</strong> Most providers bill users based on the volume of data processed, commonly measured <strong>per 1,000 or 1,000,000 tokens</strong>.</li>
<li><strong>Scalability Expenses:</strong> While easy to implement, these models are considered <strong>expensive at scale</strong>, particularly for high-traffic applications or tasks requiring <strong>long context windows</strong>.</li>
<li><strong>Commercial Licensing:</strong> In addition to usage fees, access may be governed by commercial licenses, subscription plans, or vendor-specific terms that can lead to <strong>vendor lock-in</strong>, making it difficult to migrate to other providers later.</li>
</ul>
<h3 id="2-commercial-api-pricing-for-open-source-models"><strong>2. Commercial API Pricing for Open-Source Models</strong></h3>
<ul>
<li><strong>openai/gpt-oss-120b:</strong> $0.09 per million input tokens and <strong>$0.45 per million output tokens</strong>.</li>
<li><strong>deepseek-ai/DeepSeek-R1:</strong> $0.50 per million input tokens and <strong>$2.18 per million output tokens</strong>.</li>
<li><strong>zai-org/GLM-4.5V:</strong> $0.14 per million input tokens and <strong>$0.86 per million output tokens</strong>.</li>
</ul>
<h3 id="3-perbandingan-faktor-biaya-api-vs-hosting-mandiri"><strong>3. Perbandingan Faktor Biaya: API vs. Hosting Mandiri</strong></h3>
<ul>
<li><strong>Biaya Penggunaan API:</strong> Model proprietary dan model proprietary yang di-host oleh pihak ketiga memiliki <strong>recurring API fees</strong> (biaya API berulang). model proprietary yang digunakan secara lokal <strong>tidak memiliki biaya API berulang</strong>, yang lebih hemat untuk penggunaan volume tinggi jangka panjang.</li>
<li><strong>Infrastruktur dan Pemeliharaan:</strong> Menggunakan API menghilangkan kebutuhan akan infrastruktur lokal yang mahal. Sebaliknya, menjalankan model proprietary besar (seperti Llama 3.1 405B) memerlukan <strong>infrastruktur yang kuat</strong> dan perangkat keras khusus, seperti GPU 80GB, yang mungkin tidak terjangkau bagi tim kecil.</li>
<li><strong>Beban Manajemen:</strong> API komersial menangani semua pembaruan, patch keamanan, dan penskalaan. Untuk model proprietary yang di-host sendiri, pengguna menanggung <strong>beban finansial dan tenaga kerja</strong> untuk keamanan dan pemeliharaan.</li>
</ul>






























<table><thead><tr><th align="left">Fitur</th><th align="left">API Komersial/Proprietary</th><th align="left">proprietary models (Self-Hosted)</th></tr></thead><tbody><tr><td align="left"><strong>Biaya Utama</strong></td><td align="left"><strong>Berbasis penggunaan (per token)</strong></td><td align="left"><strong>Infrastruktur &#x26; perangkat keras</strong></td></tr><tr><td align="left"><strong>Biaya API</strong></td><td align="left">Ada biaya berulang</td><td align="left"><strong>Tidak ada biaya API berulang</strong></td></tr><tr><td align="left"><strong>Pemeliharaan</strong></td><td align="left">Dikelola oleh vendor</td><td align="left">Dikelola pengguna (biaya tenaga kerja lebih tinggi)</td></tr><tr><td align="left"><strong>Skalabilitas</strong></td><td align="left">Mahal pada volume tinggi</td><td align="left">Lebih hemat untuk jangka panjang</td></tr></tbody></table>
<h3 id="sumber">Sumber:</h3>
<ul>
  <li><a href="https://jamanetwork.com/journals/jama-health-forum/fullarticle/2831206" target="_blank" rel="noopener noreferrer">Comparison of Frontier Open-Source and Proprietary Large Language Models for Complex Diagnoses</a></li>
  <li><a href="https://www.siliconflow.com/articles/en/best-open-source-LLM-for-medical-diagonisis" target="_blank" rel="noopener noreferrer">Ultimate Guide – The Best Open Source LLM for Medical Diagnosis in 2025</a></li>
  <li><a href="https://yellow.systems/blog/open-source-vs-proprietary-llms" target="_blank" rel="noopener noreferrer">Open-Source vs Proprietary LLMs: Deciding What’s Right for Your Platform</a></li>
  <li><a href="https://blog.n8n.io/open-source-llm" target="_blank" rel="noopener noreferrer">The 11 Best Open-Source LLMs for 2025</a></li>
</ul> </main> </body></html>